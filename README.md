Capstone Assignment 20.1: Initial Report and Exploratory Data Analysis (EDA)
Overview: In this module, we will work on performing exploratory data analysis (EDA) to develop an initial report for our capstone project. We will use EDA to see what data can reveal beyond the formal modeling, hypothesis testing task, and data training to provide a better understanding of dataset variables and the relationships between them. We will focus in cleaning our data and use feature engineering and EDA techniques to create visualizations to make sense of your findings. Additionally, we will use one of the ML algorithms you have learned so far in the program to develop a baseline model to use as a comparison in final Caption project.

Author: Arturo Noguera

Executive Summary: Out there every customer has plenty of options for every aquisition , we need to streght our customer´s satisfaction and loyalty. At the same time we need to reduce the probability that competitors can take over our clients. Using Data Driven go to Market strategy, we will create product bundles with more attractive prices and promote synergy among different product business units to reduce production and marketing costs.

Rationale: Our approach to this challengue is get to know each customer´s "buying profile" and target specific customers with higher probability to buy bundles from a broader portfolio vs individual products.

Research Question: Predict which customers have more probability to buy items from any category belonging to Product_Line_1 , given that they bought items from any category belonging to Product_Line_2.

Data Sources:

Sales orders received by a large IT corporation from customers located in multiple regions adquiring products from Product_Line_1 and Product_Line_2.

Each product line includes Hardware and Software, has several sublines and each subline includes multiple SKUs.

Customer is profield based in their Market Segment, Vertical Market, and Geographical region

This Dataset includes the net price for each individual transaction, during a full calendar year.

Methodology:Use cleaning and feature engineering techniques along with multiple visualizations tools to define which parts of the received information is relevant to use it in the modeling stage.

Results:
After parsing, enconding, obfuscating, cleaning ,removing incesary info, removing outliers, consolidating, reordering, and managing inbalance, we have a Data Set that is ready for the modeling phase. The final Data set "Bookings_for_Modeling.csv" is included in this repository.